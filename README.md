# Talking Head Generation
Something about Talking Head Generation

## Video driven
| Pub |  Title  |Links|
|:--------:| :-------------|:-------------:|
|CVPR(2021) | PIRenderer: Controllable Portrait Image Generation via Semantic Neural Rendering|[PDF](https://arxiv.org/pdf/2109.08379)/[code](https://github.com/RenYurui/PIRender) |
|CVPR(2022) | StyleHEAT: One-Shot High-Resolution Editable Talking Face Generation via Pre-trained StyleGAN|[PDF](https://arxiv.org/pdf/2203.04036.pdf)/[code](https://github.com/FeiiYin/StyleHEAT) |
|CVPR(2022) | Depth-Aware Generative Adversarial Network for Talking Head Video Generation|[PDF](https://arxiv.org/pdf/2203.06605)/[code](https://github.com/harlanhong/CVPR2022-DaGAN) |
| ICLR(2022)|Latent Image Animator: Learning to Animate Images via Latent Space Navigation |[PDF](https://arxiv.org/pdf/2203.09043)/[code](https://github.com/wyhsirius/LIA) |
|ECCV(2022) |Face2Face:Real-Time High-Resolution One-Shot Face Reenactment |[PDF](https://github.com/NetEase-GameAI/Face2FaceRHO/blob/master/paper.pdf)/[code](https://github.com/NetEase-GameAI/Face2FaceRHO) |
|NeurIPS(2022)|Implicit Warping for Animation with Image Sets|[PDF](https://arxiv.org/pdf/2210.01794.pdf)/[code](https://deepimagination.cc/implicit_warping/)|
|arXiv(2022) |MetaPortrait: Identity-Preserving Talking Head Generation with Fast Personalized Adaptation |[PDF](https://arxiv.org/pdf/2212.08062.pdf)/[code](https://github.com/Meta-Portrait/MetaPortrait) |
|WACV(2023) |Audio-Visual Face Reenactment |[PDF](http://cvit.iiit.ac.in/images/Projects/avfr/paper.pdf)/[code](https://github.com/mdv3101/AVFR-Gan) |


## Audio driven
| Pub |  Title  |Links| Notes|
|:--------:| :-------------|:-------------:|:-------------|
|CoRR(2020)|Audio-driven Talking Face Video Generation with Learning-based Personalized Head Pose|[PDF](http://arxiv.org/abs/2002.10137)/[code](https://github.com/yiranran/Audio-driven-TalkingFace-HeadPose) |Audio to 3D face mapping|
|IJCAI(2021)|Speech2Talking-Face: Inferring and Driving a Face with Synchronized Audio-Visual Representation|[PDF](https://www.ijcai.org/proceedings/2021/0141.pdf)/[code](https://github.com/Hangz-nju-cuhk/Talking-Face_PC-AVS)|
|IJCAI(2021)| Audio2Head: Audio-driven One-shot Talking-head Generation with Natural Head Motion |[PDF](https://arxiv.org/pdf/2107.09293)/[code](https://github.com/wangsuzhen/Audio2Head) |Audio to keypoints mapping |
|CVPR(2021)| Flow-guided One-shot Talking Face Generation with a High-resolutionAudio-visual Dataset|[PDF](https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Flow-Guided_One-Shot_Talking_Face_Generation_With_a_High-Resolution_Audio-Visual_Dataset_CVPR_2021_paper.pdf)/[code](https://github.com/MRzzm/HDTF) |Audio to 3D face mapping |
|CVPR(2021)| Audio-Driven Emotional Video Portraits |[PDF](https://arxiv.org/abs/2104.07452)/[code](https://github.com/jixinya/EVP) | Audio to face landmark|
|CVPR(2021)|Pose-Controllable Talking Face Generation by Implicitly Modularized Audio-Visual Representation |[PDF](https://arxiv.org/abs/2104.11116)/[code](https://github.com/Hangz-nju-cuhk/Talking-Face_PC-AVS) |Audio to latent code mapping |
|ICCV(2021)|FACIAL: Synthesizing Dynamic Talking Face with Implicit Attribute Learning |[PDF](https://arxiv.org/pdf/2108.07938.pdf)/[code](https://github.com/zhangchenxu528/FACIAL) |Audio to 3D face mapping |
|AAAI(2022)|One-shot Talking Face Generation from Single-speaker Audio-Visual Correlation Learning|[PDF](https://arxiv.org/pdf/2112.02749.pdf)/[code](https://github.com/FuxiVirtualHuman/AAAI22-one-shot-talking-face)|-|
|InterSpeech(2021)|Speech2Video: Cross-Modal Distillation for Speech to Video Generation |[PDF](https://arxiv.org/pdf/2107.04806v1)|-|
|ACM MM(2022)|Talking Head from Speech Audio using a Pre-trained Image Generator | [PDF](https://dl.acm.org/doi/10.1145/3503161.3548101)/[code](https://github.com/MohammedAlghamdi/talking-heads-acm-mm) |Audio to latent code mapping|
|AAAI(2022) | SyncTalkFace: Talking Face Generation with Precise Lip-syncing via Audio-Lip Memory| [PDF](https://link.zhihu.com/?target=https%3A//www.aaai.org/AAAI22Papers/AAAI-7528.ParkS.pdf)| Memory learning|
|arXiv(2022)|DFA-NeRF: Personalized Talking Head Generation via Disentangled Face Attributes Neural Rendering|[PDF](https://arxiv.org/pdf/2201.00791.pdf)/[code](https://github.com/ShunyuYao/DFA-NeRF)|Contrastive learning |
|arXiv(2022)| Perceptual Conversational Head Generation with Regularized Driver and Enhanced Renderer|[PDF](https://arxiv.org/abs/2206.12837)/[code](https://github.com/megvii-research/MM2022-ViCoPerceptualHeadGeneration) | Audio to 3D face mapping|
|arXiv(2022)|Synthesizing Photorealistic Virtual Humans Through Cross-modal Disentanglement|[PDF](https://arxiv.org/pdf/2209.01320.pdf)|- |
|arXiv(2022)|Memories are One-to-Many Mapping Alleviators in Talking Face Generation|[PDF](https://arxiv.org/abs/2212.05005v2)|Audio to 3D face mapping|
|WACV(2023) |Audio-Visual Face Reenactment |[PDF](http://cvit.iiit.ac.in/images/Projects/avfr/paper.pdf)/[code](https://github.com/mdv3101/AVFR-Gan)| Audio feature map on lip region|
|AAAI(2023) |StyleTalker: One-shot Style-based Audio-driven Talking Head Video Generation|[PDF](https://arxiv.org/pdf/2208.10922.pdf)|
|Under Review|Diffused Heads: Diffusion Models Beat GANs on Talking-Face Generation|[PDF](https://arxiv.org/pdf/2301.03396.pdf)|Diffusion Model|
|arXiv(2023)|DiffTalk: Crafting Diffusion Models for Generalized Talking Head Synthesis|[PDF](https://arxiv.org/pdf/2301.03786.pdf)/[code](https://github.com/sstzal/DiffTalk)|Diffusion Model|
|ICLR(20233)Under review|Feature-Driven Talking Face Generation With Stylegan2|[PDF](https://openreview.net/pdf?id=79xEHFvjx9p)|
|SIGGRAPH(2022)|VideoReTalking: Audio-based Lip Synchronization for Talking Head Video Editing In the Wild|[PDF](https://arxiv.org/pdf/2211.14758.pdf)/[code](https://github.com/vinthony/video-retalking)|

## Text driven
| Pub |  Title  |Links|
|:--------:| :-------------|:-------------:|
|AAAI(2021)|Write-a-speaker: Text-based Emotional and Rhythmic Talking-head Generation|[PDF](https://arxiv.org/abs/2104.07995)/[code](https://github.com/FuxiVirtualHuman/Write-a-Speaker)|
|	arXiv(2021)|Txt2vid: Ultra-low bitrate compression of talking-head videos via text|[PDF](https://arxiv.org/abs/2106.14014v3)/[code](https://github.com/tpulkit/txt2vid)|

## Dataset
| Name |  Source  |Statistics|Description|
|:--------:| :-------------:|:-------------:|:-------------|
|HDTF|https://github.com/MRzzm/HDTF |<img src="https://github.com/LTT-O/Talk-Head-Generation/blob/main/Image/HDTF.png" width="120%" height="120%" /> |High-resolution Audio-visual Dataset|
|CelebV-HQ|https://celebv-hq.github.io/ |<img src="https://github.com/LTT-O/Talk-Head-Generation/blob/main/Image/CelebV.png" width="120%" height="120%" /> |High-quality talking head dataset|
|TalkingHead-1KH|https://github.com/deepimagination/TalkingHead-1KH |	500k video clips, of which about 80k are greater than 512x512 resolution|Talking-head dataset consisting of YouTube videos|
| LRS3|https://www.robots.ox.ac.uk/~vgg/data/lip_reading/lrs3.html | <img src="https://github.com/LTT-O/Talk-Head-Generation/blob/main/Image/LRS3.png" width="120%" height="120%" />| Lip-reading recognition, including video and corresponding text|
| LRW|https://www.robots.ox.ac.uk/~vgg/data/lip_reading/lrw1.html | <img src="https://github.com/LTT-O/Talk-Head-Generation/blob/main/Image/LRW.png" width="120%" height="120%" />| Lip Reading in the Wild|
|MEAD|https://github.com/uniBruce/Mead|<img src="https://github.com/LTT-O/Talk-Head-Generation/blob/main/Image/MEAD.png" width="120%" height="120%" />|Talking Head dataset with emotion labels and intensity labels|

## Metrics
###  Image quality([code](https://github.com/chaofengc/IQA-PyTorch))
- LPIPS (Learned Perceptual Image Patch Similarity)
- PSNR (peak signal-to-noise ratio)
- SSIM (structural similarity index measure)
- FID (Fr√©chet inception distance)
- NIQE (Natural Image Quality Evaluator)

###  Identity preservation
- CSIM (cosine similarity of identity by ArcFace)

### Motion transfer quality
- AED (Average Expression Distance) 
- APD (Average Pose Distance)
- LSE-D (Lip Sync Error - Distance)
- LSE-C (Lip Sync Error - Confidence)
- LMD (landmark distance error)
- LRA (lip-reading accuracy)




